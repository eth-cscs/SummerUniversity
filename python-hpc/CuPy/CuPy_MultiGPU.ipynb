{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU Computing with [CuPy](https://cupy.chainer.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cupy as cp\n",
    "from cupy.cuda import Device as Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timers import cpu_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the number of GPUs on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_count = cp.cuda.runtime.getDeviceCount()\n",
    "print(f'The node has \"{device_count}\" CUDA GPUs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the properties of each device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = [cp.cuda.runtime.getDeviceProperties(i) for i in range(device_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(props):\n",
    "    print(f'Device {i}: {p[\"name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in props[0].items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The concept of the `Current Device`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `CuPy` makes use of the *Current Device* when performing array allocations and kernel launches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the GPU where an array resides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The current device is: {cp.cuda.get_device_id()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make use of a different device you can either use: `cupy.cuda.Device.use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device0 = Device(0)\n",
    "device1 = Device(1)\n",
    "device1.use()\n",
    "print(f'The current device is: {cp.cuda.get_device_id()}')\n",
    "device0.use()\n",
    "print(f'The current device is: {cp.cuda.get_device_id()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively an instance of `cupy.cuda.Device` can be used as a context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with device1:\n",
    "    print(f'The current device is: {cp.cuda.get_device_id()}')\n",
    "\n",
    "print(f'The current device is: {cp.cuda.get_device_id()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allocate an array on a given device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Device(1):\n",
    "    x1 = cp.zeros(1000)\n",
    "\n",
    "print(f'Array x1 is allocated on device: {x1.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CuPy handles copying of arrays between devices, using Peer-to-Peer functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Device(0):\n",
    "    array_dev0 = cp.ones((100000))\n",
    "\n",
    "with Device(1):\n",
    "    array_dev1 = cp.zeros_like(array_dev0)\n",
    "\n",
    "\n",
    "cp.copyto(array_dev1, array_dev0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Exercise</mark> Measure the bandwidth achieved when copying arrays between devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julia_kernel = cp.ElementwiseKernel('float64 X, float64 Y, float64 cx, float64 cy, int32 itermax, float64 radius2',\n",
    "                                    'int32 julia',\n",
    "                                    f'''julia = 0;\n",
    "                                    double x = X, y = Y;\n",
    "                                    double xtemp;\n",
    "                                    int nit = 0;\n",
    "                                    while(x * x + y * y < radius2 && nit < itermax) {{\n",
    "                                        xtemp = x * x - y * y + cx;\n",
    "                                        y = 2.0 * x * y + cy;\n",
    "                                        x = xtemp;\n",
    "                                        nit += 1;\n",
    "                                    }}\n",
    "                                    julia = nit;''', 'julia_kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The concept of the `Current Stream`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `CuPy` makes use of the *Current Stream* when launching operations on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use instances of `cupy.cuda.Stream` to launch kernels asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_count = 9\n",
    "rng = np.random.default_rng(29)\n",
    "complex_values = [complex(rng.uniform(-1, 1), rng.uniform(-1, 1)) for _ in range(kernel_count)]\n",
    "X, Y = cp.meshgrid(cp.linspace(-2.0 , 2.0, 5000), cp.linspace(-2.0, 2.0, 5000))\n",
    "events = [None] * kernel_count\n",
    "julia_arrays = [None] * kernel_count\n",
    "\n",
    "# Warmup\n",
    "julia_kernel(X, Y, complex_values[0].real, complex_values[0].imag, 1000, 4.0)\n",
    "\n",
    "with cpu_timer(log=True):\n",
    "    for i, c in enumerate(complex_values):\n",
    "        stream = cp.cuda.Stream(non_blocking=True)\n",
    "        with stream:\n",
    "            start = cp.cuda.Event()\n",
    "            stop = cp.cuda.Event()\n",
    "            start.record()\n",
    "            julia_arrays[i] = julia_kernel(X, Y, c.real, c.imag, 1000, 4.0)\n",
    "            stop.record()\n",
    "            events[i] = (start, stop)\n",
    "            \n",
    "    for i in range(kernel_count):\n",
    "        stop = events[i][1]\n",
    "        stop.synchronize()\n",
    "\n",
    "for i in range(kernel_count):\n",
    "    start, stop = events[i]\n",
    "    print(f'Kernel {i}: {cp.cuda.get_elapsed_time(start, stop)} ms')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i in range(kernel_count):\n",
    "    ax = fig.add_subplot(330 + i + 1)\n",
    "    julia_array = julia_arrays[i][::5, ::5].get()\n",
    "    ax.imshow(julia_array, extent=[-2, 2, -2, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-gpu kernel launching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CuPy is going to use the *Current Device* and the *Current Stream* to launch a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julia_arrays = [None] * device_count\n",
    "complex_values = [-0.9 + 0.22143j, -0.4 + 0.9j, 0.3 + 0.58j, -2.0 + 0.16j]\n",
    "events = [None] * device_count\n",
    "\n",
    "with cpu_timer():\n",
    "    for i in range(device_count):\n",
    "        with Device(i):\n",
    "            c = complex_values[i]\n",
    "            stream = cp.cuda.Stream(non_blocking=True)\n",
    "            with stream:\n",
    "                start = cp.cuda.Event()\n",
    "                stop = cp.cuda.Event()\n",
    "                start.record()\n",
    "                julia_arrays[i] = julia_kernel(*cp.meshgrid(cp.linspace(-2.0 , 2.0, 50000), cp.linspace(-2.0, 2.0, 50000)), c.real, c.imag, 10000, 4.0)\n",
    "                stop.record()\n",
    "                events[i] = (start, stop)\n",
    "            \n",
    "    for i in range(device_count):\n",
    "        with Device(i):\n",
    "            stop = events[i][1]\n",
    "            stop.synchronize()\n",
    "\n",
    "for i in range(device_count):\n",
    "    start, stop = events[i]\n",
    "    with Device(i):\n",
    "        print(f'Device {i}: {cp.cuda.get_elapsed_time(start, stop)} ms')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(device_count):\n",
    "    ax = fig.add_subplot(220 + i + 1)\n",
    "    julia_array = julia_arrays[i][::100, ::100].get()\n",
    "    ax.imshow(julia_array, extent=[-2, 2, -2, 2]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
